{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01183289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7798521c",
   "metadata": {},
   "source": [
    "# Ollama Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e99ab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text:v1.5\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2745675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.018354904, 0.0076239975, -0.16365303, 0.027597858, -0.010488409, -0.04528606, 0.015712285, -0.023781495, 0.039984096, 0.0056591905, -0.0063372045, 0.06110283, 0.046538614, -0.021614991, 0.0012997402, -0.016213425, 0.035403535, -0.069221534, -0.058882594, -0.0011242034, -0.067069806, 0.028470116, 0.0051368377, 0.01911506, 0.15101947, 0.0025551377, 0.010813687, 0.0712116, -0.0031556762, -0.00056628115, 0.051416337, -0.03502433, -0.028752772, 0.0128204, 0.014099124, 0.015710605, 0.03908029, 0.010679529, 0.059431665, -0.002328344, 0.03780426, 0.01729669, -0.033253863, -0.0049846387, 0.035980128, 0.020125758, -0.019013222, -0.026655773, 0.021744637, 0.026740199, -0.0126278065, -0.058317367, -0.041171025, -0.07536198, 0.02046362, 0.033410285, -0.0075284545, 0.04293551, 0.04508761, 0.03930286, 0.12946141, -0.021058153, -0.0386554, 0.10282171, 0.046966597, -0.05050095, -0.0083724, 0.03693413, 0.011113219, -0.058268312, 0.08540871, -0.0019113326, 0.028517418, 0.02793092, 0.003416064, -0.011821238, 0.0048537287, 0.00514391, -0.011139873, -0.043725457, 0.047486193, -0.035871554, 0.06936614, -0.013669406, 0.00276548, -0.033184394, 0.007907334, 0.027701871, -0.08888228, 0.030619008, 0.07809179, 0.02356465, -0.05078229, 0.06311594, -0.031385306, 0.032216955, -0.021268798, -0.0016943805, 0.0042499653, -0.04435536, -0.02192626, -0.0045483303, 0.0061631254, -0.022669429, 0.024383834, 0.017329054, 0.012325969, -0.049112346, -0.008661694, -0.041143302, -0.00869338, -0.0073420117, -0.030937143, -0.027071102, -0.009387793, -0.020450937, 0.025679216, -0.073631525, 0.0009812514, 0.012287062, -0.016398374, 0.012231101, 0.018293958, 0.04071477, 0.011271256, 0.015000951, -0.023814775, -0.013512317, 0.001144259, -0.043201383, -0.043818835, -0.047658946, 0.03283214, -0.009794372, 0.037972968, 0.049648482, -0.030309753, -0.039935563, -0.013696773, 0.03753317, 0.04595858, -0.004300614, -0.01808934, -0.05625838, -0.011555338, -0.04107544, 0.0672864, -0.04715147, -0.028413117, -0.018005894, 0.013126821, 0.02739627, -0.022849184, 0.015985306, 0.004626259, -0.025297616, -0.08132056, -0.03773417, 0.0069021652, -0.0049050665, 0.013566466, 0.017017713, -0.07144048, 0.07075095, -0.029044552, -0.013399813, 0.035287764, 0.056165855, 0.00628867, 0.012224962, -0.04636915, -0.029046869, -0.03430136, -0.040857222, 0.045831703, -0.04995957, -0.04143762, -0.006485541, 0.0019224306, 0.0010354797, 0.021673668, -0.046291616, -0.0002447446, 0.0010803782, -0.04138845, -0.034329697, 0.030204162, -0.043450627, -0.039236646, -0.008285702, -0.0026132495, 0.049076743, -0.04475933, -0.030909456, -0.05673707, 0.005467145, 0.009223152, -0.018770628, 0.021408083, -0.01286719, -0.08318057, -0.00599517, -0.00679833, 0.039544523, -0.010462423, 0.0070335874, 0.015335011, 0.009213764, 0.009408858, 0.04624592, 0.066682234, -0.058593377, -0.013600194, 0.0005365228, 0.015083686, -0.053605784, 0.0063063167, -0.021374328, 0.004403737, 0.023682756, 0.06891104, -0.020790046, 0.010397974, 0.005378914, 0.023394288, 0.004083368, -0.010875783, 0.019568235, -0.076630205, -0.01085282, -0.0157461, -0.04785084, 0.04432332, 0.029417263, 0.000374991, 0.06973187, -0.030988088, 0.06084159, 0.0025230863, -0.042479236, -0.050953113, 0.07888933, 0.022095717, 0.0105632385, -0.049070828, 0.0034336837, -0.012828537, -0.0037393295, 0.040575713, 0.018203812, 0.041116066, -0.015363563, 0.06212242, 0.036875308, -0.0261961, 0.0038214547, -0.03325693, -0.021819824, 0.0706974, -0.045834035, 0.04290447, -0.07654166, 0.04362863, 0.01197699, -0.041334514, 0.0140743945, -0.032996845, 0.025898812, 0.023522994, -0.012945152, 0.011854575, 0.036045164, 0.010555833, -0.012825494, -0.0025306493, 0.009580833, -0.0113096, 0.009467098, -0.039317887, 0.029069597, -0.04402472, -0.04566627, 0.010097847, -0.035361852, -0.0035256871, 0.055101365, 0.06296992, 0.07408472, -0.04631066, -0.018612634, 0.016239882, -0.011035356, -0.010777843, 0.075452484, -0.0054123527, 0.057924263, 0.09000934, -0.01504376, -0.02692515, -0.02497122, -0.0060317903, -0.00913302, -0.0060525048, 0.04768157, -0.025511019, 0.011349706, 0.013620203, -0.025097972, 0.049291383, -0.023235619, -0.040257353, 0.015471415, -0.056616183, 0.0070480895, -0.032985967, 0.019371813, -0.03383262, -0.0051185978, 0.017504836, 0.020094516, -0.043757245, -0.027956137, -0.040322565, -0.04950515, -0.010807, -0.0011806444, 0.0031291768, 0.02111943, 0.018118115, -0.007844822, 0.010392114, 0.048001017, 0.0064780274, -0.050789885, -0.033287562, 0.001341302, -0.033513278, 0.029220674, 0.029984176, 0.033514626, 0.008494054, 0.01381354, 0.028125115, -0.049270235, -0.03569716, 0.0055040326, -0.046314538, 0.0049006017, 0.04045525, 0.0023083745, -0.031800058, 0.016293934, -0.01570055, 0.010109917, -0.015848922, 0.0391665, -0.012076627, 0.017850175, 0.013325698, -0.011192806, 0.01813892, -0.040760033, 0.0014741105, -0.032303423, -0.01149082, 0.015595982, 0.05219414, 0.00836401, 0.031916454, 0.04201309, -0.01481815, -0.05252307, -0.020709295, 0.00845604, 0.025765276, 0.03334772, -0.07742774, -0.08003651, -0.021345075, 0.010644286, 0.03550659, -0.049063433, 0.06628283, 0.005098105, 0.0030962853, 0.04384641, 0.04376576, 0.04003534, 0.04311604, -0.015720397, -0.020283988, 0.009500887, 0.003225713, -0.002220162, 0.016697446, 0.015708106, 0.0334305, 0.014304066, -0.051097646, 0.04266952, -0.0066291974, -0.042101666, 0.0068512624, 0.0064765117, -0.011281898, 0.00033670024, -0.010222517, -0.029802812, 0.07539403, -0.036299244, -0.0122791035, 0.012667062, -0.006252176, -0.039264485, 0.0106414305, 0.051629107, -0.005004752, 0.02262929, -0.026683774, 0.0011021124, 0.072785825, 0.024253067, -0.026122354, -0.049845632, -0.0054474417, 0.033475213, 0.056933243, 0.0050934586, 0.008699153, -0.03742061, 0.017399268, 0.026513401, -0.02396003, 0.018882621, -0.013765185, -0.036908258, 0.011365584, -0.019936465, 0.035770603, 0.047588747, 0.0454736, -0.040255226, -0.05695883, 0.018669678, -0.030832682, 0.059661508, 0.061242785, -0.008518617, -0.010451985, 0.012864035, -0.05491566, 0.025790397, 0.07081478, 0.024779486, 0.11170351, -0.08669808, -0.006806393, -0.045531716, 0.016833764, -0.004184236, 0.01770878, 0.015676893, -0.06957801, 0.0044681598, 0.008596654, -0.04264001, -0.008342599, -0.010070625, 0.052018236, 0.00704229, -0.019210367, 0.021061284, 0.055363104, -0.02598856, -0.034758992, -0.030300612, -0.06316196, -0.0063787135, 0.0017760278, 0.07641914, 0.018030439, -0.008034616, -0.04166402, -0.11869096, 0.026615376, 0.033760313, 0.02159386, 0.004267022, -0.0017378605, 0.045785684, 0.005640582, -0.001839674, -0.01159085, 0.008740043, 0.004945989, -0.030979583, -0.04040841, 0.007772737, 0.0037014806, 0.0039106063, 0.004634841, -0.006866705, -0.051191296, 0.009427534, 0.020495918, -0.050820395, 0.041990083, -0.03618747, 0.004919311, 0.014791334, -0.046526264, -0.00073567807, -0.019502595, 0.024572378, -0.009029874, -0.0039096805, 0.04747843, 0.044573452, -0.051946554, 0.0617454, -0.025770705, -0.060706403, -0.008291227, -0.03234178, -0.05603468, 0.028865542, -0.0011549017, -0.03816782, 0.014713637, 0.014781933, -0.009833256, -0.011026609, -0.0014243948, -0.02214541, -0.004724557, -0.022403944, -0.03492756, 0.027905473, 0.029780094, 0.005516111, 0.027252268, 0.00017077859, 0.041795082, -0.006400416, -0.004898605, 0.018264275, -0.05015929, -0.021854037, 0.045860626, 0.0111104995, 0.035087056, -0.07044739, -0.024937747, 0.02029712, -0.02292258, -0.044737875, -0.03530253, 0.0107564, -0.02844402, 0.0021454585, 0.007848896, 0.004177199, 0.032022547, -0.05765723, 0.026623257, -0.008306345, -0.00940105, -0.04449494, 0.009491819, 0.025148658, -0.007383165, -0.0404833, 0.07345433, 0.01243094, 0.0061950963, 0.037744608, 0.035089087, 0.000887926, -0.07398058, -0.060669623, 0.0011033327, -0.10154151, 0.0708351, 0.048217047, -0.0033015402, 0.004992278, 0.0005189941, -0.054819267, 0.0041534835, -0.024833642, -0.012608389, -0.010953594, -0.007218603, -0.017399024, -0.007285758, -0.020235863, -0.010656657, -0.0018951319, -0.0016822448, 0.02020918, -0.012903415, 0.01375838, 0.03014488, -0.00027960408, -0.013981279, 0.011347045, -0.024049465, 0.028846575, -0.010538523, -0.019040963, 0.039539732, 0.031034315, -0.013981649, 0.0021841775, 0.024659932, -0.00049016904, 0.02081824, 0.04310427, 0.03283752, 0.005841321, -0.010125997, -0.010682948, 0.04497322, -0.009551731, 0.0031668597, -0.00759456, -0.05325072, -0.006630845, -0.015902484, 0.012417355, -0.018767048, -0.042312585, -0.046332046, -0.02427794, -0.0114157805, -0.00664094, 0.019604634, 0.013826395, 0.024110308, 0.008288707, -0.034309324, -0.039246947, -0.033328008, -0.0044449777, 0.06533431, -0.022315428, 0.025529379, 0.019572346, 0.07241905, -3.6113765e-05, 0.08332397, 0.054951016, 0.03728151, -0.0037482106, 0.021177234, 0.0003113221, -0.00088033185, -0.05509585, -0.036072463, -0.006710386, 0.0022081228, 0.058929406, 0.0029852672, -0.031767607, 0.018803705, 0.038688216, -0.03573154, -0.02461728, -0.080581866, -0.029509867, 0.013161582, -0.042973153, 0.01846736, 0.0020012162, 0.0023430863, 0.04360646, 0.03516466, 0.058833983, 0.01991989, 0.007800515, 0.049967762, -0.042183712, -0.02035195, 0.03640269, 0.03490197, -0.00974016, 0.07162667, -0.07266829, 0.012218712, -0.05793238, 0.01154651, -0.048454445, -0.01690727, -0.022981342, 0.003793279, 0.00873111, -0.051616352, -0.036167488, -0.07196519, 0.070884936, 0.027604304, 0.06716855, 0.01976502, 0.029547099, -0.02128062, -0.0011814325, 0.051677812, 0.012935652, 0.037878722, 0.007101566, 0.01817351, -0.019366466, -0.035330404, 0.05415062, 0.09410211, 0.0026788837, -0.046705384, 0.005679581, -0.028877683, 0.033024736, 0.08358948, -0.027425442, -0.03171709, -0.025013559, -0.017849486, -0.011242501, 0.025471916, -0.051841598, -0.0063585853, 0.0033999125, 0.018390927, -0.016287142, -0.058890328, 0.015228608, -0.0012107427, 0.025773011, -0.037043504, -0.01598345, -0.05513557, -0.026084505, -0.05226793, -0.0036983876, 0.02462377, 0.021172678, -0.0041846596, -0.00415536, -0.03544223, 0.026046265, 0.01807351, -0.031568617, -0.008986823, -0.0069357567, -0.003596589, 0.00967883, 0.07194816, 0.027635112, 0.010893729, 0.04499962, 0.13102908, -0.0033974457, 0.009967444, -0.013197738, -0.0010996758, 0.024834462, -0.012035214, -0.016860174, -0.0398916, -0.017855333]\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "text = \"Hi, this is Vinay Ram Gazula!\"\n",
    "\n",
    "single_vector = embeddings.embed_query(text)\n",
    "print(single_vector)\n",
    "print(len(single_vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c00d5c",
   "metadata": {},
   "source": [
    "# Ollama LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aa61795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Step‑by‑step explanation of “What is LangChain?”**\\n\\n---\\n\\n### 1. Identify the domain\\n- **LangChain** belongs to the field of **generative AI / large language model (LLM) tooling**.  \\n- It is a **framework** that helps developers build applications that are powered by LLMs (e.g., OpenAI’s GPT‑4, Anthropic’s Claude, LLaMA, etc.).\\n\\n### 2. Core purpose\\n- The main goal of LangChain is to **make it easier to create “chains” of operations** that combine LLM calls with other computational steps (e.g., data retrieval, transformation, tool usage, memory, routing).\\n\\n### 3. Key concepts (the building blocks)\\n| Concept | What it does | Example |\\n|---------|--------------|---------|\\n| **PromptTemplate** | Standardizes how prompts are constructed and rendered. | Fill a template with a user query and context. |\\n| **LLM** | Wrapper around any language model API (OpenAI, Azure, HuggingFace, etc.). | `OpenAI(model=\"gpt-4\")`. |\\n| **Chain** | A sequence of components (LLM → post‑processor → another LLM, etc.). | “Answer question → summarize → store in vector DB”. |\\n| **Agent** | Dynamically decides which tool or chain to invoke based on the LLM’s output. | A chatbot that can browse the web, run code, or query a database. |\\n| **Memory** | Persists conversation state across turns. | Keep track of prior user inputs for context. |\\n| **Retriever / VectorStore** | Retrieves relevant documents from a knowledge base to augment prompts. | Use Pinecone or FAISS to fetch relevant passages. |\\n| **Tool** | External function the LLM can call (e.g., calculator, API request). | `search_web(query)`, `run_python(code)`. |\\n\\n### 4. How it works (a simple flow)\\n1. **Input** – User sends a query.  \\n2. **Prompt creation** – `PromptTemplate` fills a prompt with the query and any retrieved context.  \\n3. **LLM call** – The prompt is sent to the selected LLM via the `LLM` wrapper.  \\n4. **Post‑processing** – The raw LLM output may be parsed, filtered, or fed into another component.  \\n5. **Optional chaining** – The result can trigger additional steps (e.g., store in a DB, call a tool, loop back).  \\n6. **Output** – The final answer is returned to the user.\\n\\n### 5. Typical use‑cases\\n- **Retrieval‑augmented generation (RAG)** – Combine vector‑store retrieval with LLM answering.  \\n- **Chatbots with tool use** – Agents that can browse the web, run code, or query APIs.  \\n- **Data extraction / transformation pipelines** – Use LLMs to parse PDFs, emails, etc., then feed results into downstream systems.  \\n- **Workflow automation** – Chain LLM reasoning with business logic (e.g., generate a report, then email it).  \\n\\n### 6. Ecosystem & integrations\\n- **Supported LLM providers**: OpenAI, Azure OpenAI, Anthropic, Cohere, HuggingFace, etc.  \\n- **Vector stores**: Pinecone, Weaviate, FAISS, Chroma, Milvus, etc.  \\n- **Frameworks**: Works with LangChain’s Python, JavaScript/TypeScript, and (in preview) Go libraries.  \\n- **Community**: Open‑source on GitHub, extensive docs, tutorials, and a growing set of community‑contributed “components”.\\n\\n### 7. Why developers choose LangChain\\n- **Modularity** – Plug‑and‑play components; you can swap out the LLM, retriever, or memory without rewriting code.  \\n- **Abstraction of boilerplate** – Handles prompt formatting, token limits, retries, streaming, etc.  \\n- **Scalability** – Designed to work in production (async support, batching, logging).  \\n- **Extensibility** – Easy to add custom tools, agents, or chain steps.\\n\\n### 8. Quick code sketch (Python)  \\n```python\\nfrom langchain import OpenAI, PromptTemplate, LLMChain, FAISS, OpenAIEmbeddings\\n\\n# 1. Set up LLM\\nllm = OpenAI(model=\"gpt-4\")\\n\\n# 2. Define a prompt template\\ntemplate = PromptTemplate(\\n    input_variables=[\"question\", \"context\"],\\n    template=\"Answer the question using the context below.\\\\n\\\\nContext: {context}\\\\n\\\\nQuestion: {question}\"\\n)\\n\\n# 3. Create a vector store for retrieval\\nembeddings = OpenAIEmbeddings()\\nvector_store = FAISS.from_texts(\\n    [\"Document 1 text...\", \"Document 2 text...\"], embeddings\\n)\\n\\n# 4. Build a retrieval‑augmented chain\\nretrieval_chain = LLMChain(\\n    llm=llm,\\n    prompt=template,\\n    retriever=vector_store.as_retriever()\\n)\\n\\n# 5. Run it\\nanswer = retrieval_chain.run({\"question\": \"What is LangChain?\"})\\nprint(answer)\\n```\\n*The snippet shows how LangChain ties together a retriever, a prompt, and an LLM in just a few lines.*\\n\\n### 9. Summary\\n- **LangChain = a modular framework for building LLM‑centric applications**.  \\n- It lets you **chain together prompts, retrieval, memory, tools, and agents** to create sophisticated, production‑ready AI systems without reinventing the plumbing each time.\\n\\n--- \\n\\nThat’s the step‑by‑step breakdown of what LangChain is and how it fits into the AI development landscape.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = OllamaLLM(model=\"gpt-oss:120b-cloud\", temperature=0.0)\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "chain.invoke({\"question\": \"What is LangChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651da561",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lakehouse-RAG (3.11.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
