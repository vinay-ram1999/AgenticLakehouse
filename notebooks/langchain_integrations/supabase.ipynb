{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19806d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c095b522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_community.vectorstores import SupabaseVectorStore\n",
    "from supabase.client import Client, create_client\n",
    "\n",
    "supabase_url = os.environ.get(\"SUPABASE_URL\")\n",
    "supabase_key = os.environ.get(\"SUPABASE_KEY\")\n",
    "supabase: Client = create_client(supabase_url, supabase_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d47a73b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759553277.472577 1182373 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "E0000 00:00:1759553277.509995 1182373 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b0fbd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 510, which is longer than the specified 500\n",
      "Created a chunk of size 896, which is longer than the specified 500\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "loader = TextLoader(\"../../data/dummy.txt\")\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca2cdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = SupabaseVectorStore.from_documents(\n",
    "    docs,\n",
    "    embeddings,\n",
    "    client=supabase,\n",
    "    table_name=\"documents_temp\",\n",
    "    query_name=\"match_documents\",\n",
    "    chunk_size=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d095a611",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How to implement SupabaseVectorStore in langchain?\"\n",
    "matched_docs = vector_store.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "598d22fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from langchain_community.vectorstores import SupabaseVectorStore\n",
      "from langchain_openai import OpenAIEmbeddings\n",
      "from supabase.client import Client, create_client\n",
      "\n",
      "supabase_url = os.environ.get(\"SUPABASE_URL\")\n",
      "supabase_key = os.environ.get(\"SUPABASE_SERVICE_KEY\")\n",
      "supabase: Client = create_client(supabase_url, supabase_key)\n",
      "\n",
      "embeddings = OpenAIEmbeddings()\n",
      "\n",
      "Next we'll load and parse some data for our vector store (skip if you already have documents with embeddings stored in your DB).\n"
     ]
    }
   ],
   "source": [
    "print(matched_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3295d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_docs = vector_store.similarity_search_with_relevance_scores(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1ca12b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Document(metadata={'source': '../../data/dummy.txt'}, page_content='from langchain_community.vectorstores import SupabaseVectorStore\\nfrom langchain_openai import OpenAIEmbeddings\\nfrom supabase.client import Client, create_client\\n\\nsupabase_url = os.environ.get(\"SUPABASE_URL\")\\nsupabase_key = os.environ.get(\"SUPABASE_SERVICE_KEY\")\\nsupabase: Client = create_client(supabase_url, supabase_key)\\n\\nembeddings = OpenAIEmbeddings()\\n\\nNext we\\'ll load and parse some data for our vector store (skip if you already have documents with embeddings stored in your DB).'),\n",
       " 0.911848967561228)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74c71fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a39c52e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_docs = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9fc5206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Document 0\n",
      "\n",
      "from langchain_community.vectorstores import SupabaseVectorStore\n",
      "from langchain_openai import OpenAIEmbeddings\n",
      "from supabase.client import Client, create_client\n",
      "\n",
      "supabase_url = os.environ.get(\"SUPABASE_URL\")\n",
      "supabase_key = os.environ.get(\"SUPABASE_SERVICE_KEY\")\n",
      "supabase: Client = create_client(supabase_url, supabase_key)\n",
      "\n",
      "embeddings = OpenAIEmbeddings()\n",
      "\n",
      "Next we'll load and parse some data for our vector store (skip if you already have documents with embeddings stored in your DB).\n",
      "\n",
      "## Document 1\n",
      "\n",
      "Alternatively if you already have documents with embeddings in your database, simply instantiate a new SupabaseVectorStore directly:\n",
      "\n",
      "vector_store = SupabaseVectorStore(\n",
      "    embedding=embeddings,\n",
      "    client=supabase,\n",
      "    table_name=\"documents\",\n",
      "    query_name=\"match_documents\",\n",
      ")\n",
      "\n",
      "Finally, test it out by performing a similarity search:\n",
      "\n",
      "query = \"What did the president say about Ketanji Brown Jackson\"\n",
      "matched_docs = vector_store.similarity_search(query)\n",
      "\n",
      "print(matched_docs[0].page_content)\n",
      "\n",
      "## Document 2\n",
      "\n",
      "Supabase is an open-source Firebase alternative. Supabase is built on top of PostgreSQL, which offers strong SQL querying capabilities and enables a simple interface with already-existing tools and frameworks.\n",
      "\n",
      "PostgreSQL also known as Postgres, is a free and open-source relational database management system (RDBMS) emphasizing extensibility and SQL compliance.\n",
      "\n",
      "This notebook shows how to use Supabase and pgvector as your VectorStore.\n",
      "\n",
      "## Document 3\n",
      "\n",
      "# with pip\n",
      "%pip install --upgrade --quiet  supabase\n",
      "\n",
      "# with conda\n",
      "# !conda install -c conda-forge supabase\n",
      "\n",
      "We want to use OpenAIEmbeddings so we have to get the OpenAI API Key.\n",
      "\n",
      "import getpass\n",
      "import os\n",
      "\n",
      "if \"OPENAI_API_KEY\" not in os.environ:\n",
      "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n",
      "\n",
      "if \"SUPABASE_URL\" not in os.environ:\n",
      "    os.environ[\"SUPABASE_URL\"] = getpass.getpass(\"Supabase URL:\")\n"
     ]
    }
   ],
   "source": [
    "for i, d in enumerate(matched_docs):\n",
    "    print(f\"\\n## Document {i}\\n\")\n",
    "    print(d.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e6a7dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2073340e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469ac457",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lakehouse-RAG (3.11.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
