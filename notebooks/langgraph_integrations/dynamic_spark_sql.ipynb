{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed964386",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# llm_model = ChatGroq(name=\"spark_sql\", model=\"openai/gpt-oss-120b\", temperature=0.0)\n",
    "llm_model = ChatOllama(name=\"spark_sql\", model=\"gpt-oss:120b-cloud\", temperature=0.0)\n",
    "\n",
    "from langchain_community.tools.spark_sql.tool import ( InfoSparkSQLTool, ListSparkSQLTool, QuerySparkSQLTool, QueryCheckerTool, )\n",
    "from langchain_community.agent_toolkits import SparkSQLToolkit\n",
    "from langchain_community.utilities.spark_sql import SparkSQL\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from pyspark.sql.connect.client.core import SparkConnectGrpcException\n",
    "from databricks.connect import DatabricksSession\n",
    "\n",
    "catalog = os.environ.get(\"UC_CATALOG_NAME\")\n",
    "schema = os.environ.get(\"UC_SCHEMA_NAME\")\n",
    "\n",
    "# --- Session factory ---\n",
    "def get_spark_session():\n",
    "    \"\"\"Get or create a live Databricks Serverless SparkSession.\"\"\"\n",
    "    try:\n",
    "        spark = DatabricksSession.builder.getOrCreate()\n",
    "    except SparkConnectGrpcException:\n",
    "        spark = DatabricksSession.builder.create()\n",
    "    return spark\n",
    "\n",
    "# --- Dynamic subclasses ---\n",
    "class DynamicQuerySparkSQLTool(QuerySparkSQLTool):\n",
    "    \"\"\"Dynamic variant of QuerySparkSQLTool with auto-refreshing SparkSession.\"\"\"\n",
    "\n",
    "    def _run(self, query: str, **kwargs):\n",
    "        _spark = get_spark_session()\n",
    "        self.db = SparkSQL(spark_session=_spark, catalog=catalog, schema=schema)\n",
    "        return super()._run(query, **kwargs)\n",
    "\n",
    "\n",
    "class DynamicInfoSparkSQLTool(InfoSparkSQLTool):\n",
    "    \"\"\"Dynamic variant of InfoSparkSQLTool.\"\"\"\n",
    "\n",
    "    def _run(self, table_names: str, **kwargs):\n",
    "        _spark = get_spark_session()\n",
    "        self.db = SparkSQL(spark_session=_spark, catalog=catalog, schema=schema)\n",
    "        return super()._run(table_names, **kwargs)\n",
    "\n",
    "\n",
    "class DynamicListSparkSQLTool(ListSparkSQLTool):\n",
    "    \"\"\"Dynamic variant of ListSparkSQLTool.\"\"\"\n",
    "\n",
    "    def _run(self, tool_input: str = \"\", **kwargs):\n",
    "        _spark = get_spark_session()\n",
    "        self.db = SparkSQL(spark_session=_spark, catalog=catalog, schema=schema)\n",
    "        return super()._run(tool_input, **kwargs)\n",
    "\n",
    "\n",
    "class DynamicQueryCheckerTool(QueryCheckerTool):\n",
    "    \"\"\"Dynamic variant of QueryCheckerTool.\"\"\"\n",
    "\n",
    "    def _run(self, query: str, **kwargs):\n",
    "        _spark = get_spark_session()\n",
    "        self.db = SparkSQL(spark_session=_spark, catalog=catalog, schema=schema)\n",
    "        return super()._run(query, **kwargs)\n",
    "\n",
    "    async def _arun(self, query: str, **kwargs):\n",
    "        _spark = get_spark_session()\n",
    "        self.db = SparkSQL(spark_session=_spark, catalog=catalog, schema=schema)\n",
    "        return await super()._arun(query, **kwargs)\n",
    "\n",
    "spark = get_spark_session()\n",
    "spark_sql = SparkSQL(spark_session=spark, catalog=catalog, schema=schema)\n",
    "\n",
    "query_spark_tool = DynamicQuerySparkSQLTool(db=spark_sql)\n",
    "info_spark_tool = DynamicInfoSparkSQLTool(db=spark_sql)\n",
    "list_spark_tool = DynamicListSparkSQLTool(db=spark_sql)\n",
    "check_spark_tool = DynamicQueryCheckerTool(db=spark_sql, llm=llm_model)\n",
    "\n",
    "tool_objects = [query_spark_tool, info_spark_tool, list_spark_tool, check_spark_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d28d4755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a helpful databricks lakehouse assistant primarily used for exploring the databricks workspace artifacts by leveraging Unity Catalog and SparkSQL.\n",
    "The databricks unity catalog follows a three-level namespace '<catalog>.<schema>.<table>' make sure you adhere to this while using the tools.\n",
    "\n",
    "Help the users by answering their questions using the appropriate tools.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "Assist the user with their question.\n",
    "\n",
    "IMPORTANT: Only output the required message, no other explanation or text can be provided.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"user\", user_prompt),\n",
    "        # Placeholders fill up a **list** of messages\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab34bc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/vf9_pm5d76v6svcvw6l13dv00000gn/T/ipykernel_76825/1933583795.py:8: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  tools = [tool_object.as_tool() for tool_object in tool_objects]\n"
     ]
    }
   ],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver \n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.errors import GraphRecursionError\n",
    "\n",
    "RECURSION_LIMIT = 5\n",
    "\n",
    "memory = MemorySaver()\n",
    "tools = [tool_object.as_tool() for tool_object in tool_objects]\n",
    "\n",
    "langgraph_agent_executor = create_react_agent(llm_model, tools, prompt=system_prompt, checkpointer=memory)\n",
    "langgraph_agent_executor.step_timeout = None\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"test-thread\"}}\n",
    "query = \"List all the tables present.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42de1f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'gpt-oss:120b-cloud', 'created_at': '2025-10-10T00:19:54.785970335Z', 'done': True, 'done_reason': 'stop', 'total_duration': 726446427, 'load_duration': None, 'prompt_eval_count': 596, 'prompt_eval_duration': None, 'eval_count': 50, 'eval_duration': None, 'model_name': 'gpt-oss:120b-cloud'}, id='run--916d5b93-ab2d-4088-b66c-bf21f0c55d0d-0', tool_calls=[{'name': 'list_tables_sql_db', 'args': {'tool_input': ''}, 'id': '94d5add7-3830-47f5-9e30-36839f95899f', 'type': 'tool_call'}], usage_metadata={'input_tokens': 596, 'output_tokens': 50, 'total_tokens': 646}),\n",
       "  ToolMessage(content='customer, lineitem, nation, orders, part, partsupp, region, supplier', name='list_tables_sql_db', id='b52a677f-7cc1-47bc-baeb-c96ef3f3b068', tool_call_id='94d5add7-3830-47f5-9e30-36839f95899f'),\n",
       "  AIMessage(content='I’m ready to help! What would you like to know or explore in the Databricks workspace?', additional_kwargs={}, response_metadata={'model': 'gpt-oss:120b-cloud', 'created_at': '2025-10-10T00:19:56.822373272Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1109813223, 'load_duration': None, 'prompt_eval_count': 650, 'prompt_eval_duration': None, 'eval_count': 47, 'eval_duration': None, 'model_name': 'gpt-oss:120b-cloud'}, id='run--290eaf74-71b8-4734-b960-9e13a3f45e6b-0', usage_metadata={'input_tokens': 650, 'output_tokens': 47, 'total_tokens': 697})]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = langgraph_agent_executor.invoke({\"query\": query}, config=config)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71963e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'gpt-oss:120b-cloud', 'created_at': '2025-10-10T00:19:54.785970335Z', 'done': True, 'done_reason': 'stop', 'total_duration': 726446427, 'load_duration': None, 'prompt_eval_count': 596, 'prompt_eval_duration': None, 'eval_count': 50, 'eval_duration': None, 'model_name': 'gpt-oss:120b-cloud'}, id='run--916d5b93-ab2d-4088-b66c-bf21f0c55d0d-0', tool_calls=[{'name': 'list_tables_sql_db', 'args': {'tool_input': ''}, 'id': '94d5add7-3830-47f5-9e30-36839f95899f', 'type': 'tool_call'}], usage_metadata={'input_tokens': 596, 'output_tokens': 50, 'total_tokens': 646}),\n",
       "  ToolMessage(content='customer, lineitem, nation, orders, part, partsupp, region, supplier', name='list_tables_sql_db', id='b52a677f-7cc1-47bc-baeb-c96ef3f3b068', tool_call_id='94d5add7-3830-47f5-9e30-36839f95899f'),\n",
       "  AIMessage(content='I’m ready to help! What would you like to know or explore in the Databricks workspace?', additional_kwargs={}, response_metadata={'model': 'gpt-oss:120b-cloud', 'created_at': '2025-10-10T00:19:56.822373272Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1109813223, 'load_duration': None, 'prompt_eval_count': 650, 'prompt_eval_duration': None, 'eval_count': 47, 'eval_duration': None, 'model_name': 'gpt-oss:120b-cloud'}, id='run--290eaf74-71b8-4734-b960-9e13a3f45e6b-0', usage_metadata={'input_tokens': 650, 'output_tokens': 47, 'total_tokens': 697}),\n",
       "  AIMessage(content='Sure thing! Let me know what you’d like to explore—whether it’s the schema of a specific table, running a query across the available tables (customer, lineitem, nation, orders, part, partsupp, region, supplier), or anything else you need help with in the Databricks workspace.', additional_kwargs={}, response_metadata={'model': 'gpt-oss:120b-cloud', 'created_at': '2025-10-10T00:19:58.040599979Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1081885012, 'load_duration': None, 'prompt_eval_count': 677, 'prompt_eval_duration': None, 'eval_count': 98, 'eval_duration': None, 'model_name': 'gpt-oss:120b-cloud'}, id='run--99ece08f-66ad-4a1c-af92-68975fb98fde-0', usage_metadata={'input_tokens': 677, 'output_tokens': 98, 'total_tokens': 775})]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"List the top 3 nations based on the total number of customers from that nation.\"\n",
    "out = langgraph_agent_executor.invoke({\"query\": query}, config=config)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30a454cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'customer, lineitem, nation, orders, part, partsupp, region, supplier'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_spark_tool.run(tool_input=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a102b8c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CREATE TABLE tpch.bronze.customer (\\n  c_custkey BIGINT,\\n  c_name STRING,\\n  c_address STRING,\\n  c_nationkey BIGINT,\\n  c_phone STRING,\\n  c_acctbal DECIMAL(18,2),\\n  c_mktsegment STRING,\\n  c_comment STRING)\\n;\\n\\n/*\\n3 rows from customer table:\\nc_custkey\\tc_name\\tc_address\\tc_nationkey\\tc_phone\\tc_acctbal\\tc_mktsegment\\tc_comment\\n412445\\tCustomer#000412445\\t0QAB3OjYnbP6mA0B,kgf\\t21\\t31-421-403-4333\\t5358.33\\tBUILDING\\tarefully blithely regular epi\\n412446\\tCustomer#000412446\\t5u8MSbyiC7J,7PuY4Ivaq1JRbTCMKeNVqg \\t20\\t30-487-949-7942\\t9441.59\\tMACHINERY\\tsleep according to the fluffily even forges. fluffily careful packages after the ironic, silent deposi\\n412447\\tCustomer#000412447\\tHC4ZT62gKPgrjr ceoaZgFOunlUogr7GO\\t7\\t17-797-466-6308\\t7868.75\\tAUTOMOBILE\\taggle blithely among the carefully express excus\\n*/\\n\\nCREATE TABLE tpch.bronze.lineitem (\\n  l_orderkey BIGINT,\\n  l_partkey BIGINT,\\n  l_suppkey BIGINT,\\n  l_linenumber INT,\\n  l_quantity DECIMAL(18,2),\\n  l_extendedprice DECIMAL(18,2),\\n  l_discount DECIMAL(18,2),\\n  l_tax DECIMAL(18,2),\\n  l_returnflag STRING,\\n  l_linestatus STRING,\\n  l_shipdate DATE,\\n  l_commitdate DATE,\\n  l_receiptdate DATE,\\n  l_shipinstruct STRING,\\n  l_shipmode STRING,\\n  l_comment STRING)\\n;\\n\\n/*\\n3 rows from lineitem table:\\nl_orderkey\\tl_partkey\\tl_suppkey\\tl_linenumber\\tl_quantity\\tl_extendedprice\\tl_discount\\tl_tax\\tl_returnflag\\tl_linestatus\\tl_shipdate\\tl_commitdate\\tl_receiptdate\\tl_shipinstruct\\tl_shipmode\\tl_comment\\n15997987\\t295335\\t20346\\t4\\t50.00\\t66516.00\\t0.01\\t0.08\\tA\\tF\\t1992-02-12\\t1992-04-22\\t1992-03-10\\tTAKE BACK RETURN\\tREG AIR\\t even pinto beans. ironic reque\\n15997988\\t332059\\t19578\\t1\\t49.00\\t53460.96\\t0.08\\t0.03\\tA\\tF\\t1994-05-31\\t1994-06-20\\t1994-06-22\\tNONE\\tFOB\\tdetect carefully. idly r\\n15997988\\t904286\\t4287\\t2\\t37.00\\t47738.88\\t0.07\\t0.05\\tA\\tF\\t1994-05-24\\t1994-05-28\\t1994-06-03\\tCOLLECT COD\\tRAIL\\t the slyly e\\n*/'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_spark_tool.run(tool_input=\"customer, lineitem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b1ec92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lakehouse-RAG (3.11.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
